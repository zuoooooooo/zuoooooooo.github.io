---
layout: archive
title: "Research"
permalink: /Research/
author_profile: true
---

{% include base_path %}

----------------

We are organizing a **Deep Learning Seminar**, focusing on discussions around deep neural networks, large language models,  and generative models. For more information, please visit: [https://zuoooooooo.github.io/dlseminar.html](https://zuoooooooo.github.io/dlseminar.html)



---------------
**How well can we classify** （with Zhouyu Shen and Dacheng Xiu）           
<span style="color:grey">Work in progress .</span> 

Abstract: In high-dimensional logistic regressions with weak signals, we investigate the predictive performance of maximum likelihood estimators with shrinkage. Our theory shows that both Ridge- and Lasso-regularized MLEs improve upon a zero benchmark, yet Lasso consistently underperforms Ridge. Strikingly, we uncover a failure of tuning in Ridge: predictive gains are invariant to the choice of penalty parameter. This breakdown highlights a fundamental contrast between weak and strong signals, suggesting that the challenge of prediction in weak-signal settings lies not in tuning but in the intrinsic limits of information extraction. These findings deepen our understanding of the difficulties posed by weak signals in economic and social data.



---------------

**An Efficient Pruner for Large Language Model with Theoretical Guarantee** （with Canhong Wen and Wenliang Pan）           
<span style="color:grey">*International Conference on Machine Learning* (ICML), 2025.</span> 
[[icml](https://icml.cc/virtual/2025/poster/44100)] [[openreview](https://openreview.net/pdf?id=nh9mBCYeF7)]


Abstract: Large Language Models (LLMs) have showcased remarkable performance across a range of tasks but are hindered by their massive parameter sizes, which impose significant computational and storage demands. Pruning has emerged as an effective solution to reduce model size, but traditional methods often involve inefficient retraining or rely on heuristic-based one-shot approaches that lack theoretical guarantees. In this paper, we reformulate the pruning problem as an $\ell_0$-penalized optimization problem and propose a monotone accelerated Iterative Hard Thresholding (mAIHT) method. Our approach combines solid theoretical foundations with practical effectiveness, offering a detailed theoretical analysis that covers convergence, convergence rates, and risk upper bounds. Through extensive experiments, we demonstrate that mAIHT outperforms state-of-the-art pruning techniques by effectively pruning the LLaMA-7B model across various evaluation metrics.

---------------
  
